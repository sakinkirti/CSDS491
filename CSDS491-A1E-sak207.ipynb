{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploration (40 pts)\n",
    "\n",
    "In these problems, you are meant to do creative exploration.  Define and explore:\n",
    "\n",
    "E.1 A discrete inference problem (20 pts)\n",
    "\n",
    "E.2 A continuous inference problem (20 pts)\n",
    "\n",
    "This is meant to be open-ended; you should not feel the need to write a book chapter; but neither should you just change the numbers in one of the problems above.  After doing the readings and problems above, you should pick a concept you want to understand better or an simple modeling idea you want to try out.  You can also start to explore ideas for your project.  The general idea is for you to teach yourself (and potentially a classate) about a concept from the assignments and readings or solidify your understanding of required technical background. For additional guidance, see the grading rubric below.\n",
    "\n",
    "You can use the readings and other sources for inspiration, but here are a few ideas:\n",
    "- An inference problem using categorical data\n",
    "- A disease for which there are two different tests\n",
    "- A two-dimensional continuous inference problem\n",
    "- The idea of a conjugate prior\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration Grading Rubric\n",
    "\n",
    "Exploration problems will be graded according the elements in the table below.  The scores in the column headers indicate the number of points possible for each rubric element (given in the rows).  A score of zero for an element is possible if it is missing entirely.\n",
    "\n",
    "|     | Substandard (+1) | Basic (+2) | Good (+3) | Excellent (+5) |\n",
    "| :-- | :----------- | :---- | :--- | :-------- |\n",
    "| <b> Pedagogical Value </b> | No clear statement of idea or concept being explored or explained; lack of motivating questions. | Simple problem with adequate motivation; still could be a useful addition to an assignment. | Good choice of problem with effective illustrations of concept(s).  Demonstrates a deeper level of understanding. | Problem also illustrates or clarifies common conceptual difficulties or misconceptions. |\n",
    "| <b> Novelty of Ideas </b> | Copies existing problem or makes only a trivial modification; lack of citation(s) for source of inspiration. | Concepts are similar to those covered in the assignment but with some modifications of an existing exericse. | Ideas have clear pedagogical motivation; creates different type of problem or exercise to explore related or foundational concepts more deeply. | Applies a technique or explores concept not covered in the assignment or not discussed at length in lecture. | \n",
    "| <b> Clarity of Explanation </b> | Little or confusing explanation; figures lack labels or useful captions; no explanation of motivations. | Explanations are present, but unclear, unfocused, wordy or contain too much technical detail. | Clear and concise explanations of key ideas and motivations. | Also clear and concise, but includes illustrative figures; could be read and understood by students from a variety of backgrounds. |\n",
    "| <b> Depth of Exploration </b> | Content is obvious or closely imitates assignment problems. | Uses existing problem for different data. | Applies a variation of a technique to solve a problem with an interesting motivation; explores a concept in a series of related problems. | Applies several concepts or techniques; has clear focus of inquiry that is approached from multiple directions.|"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exploration Introduction\n",
    "It has been several years since I have looked in-depth at probability. I therefore, wanted to use this Exploration to refresh my knowledge via somewhat complex/new inference problems. Below, I look at one example of a discrete inference problem and one example of a continuous inference problem, while trying to uncover and refresh some basic knowledge for myself."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.1 A discrete Inference Problem\n",
    "Consider the case where you draw three cards from a standard 52-card deck where the values of the cards for ambiguous cards are as follows: Ace = 1, Jack = 11, Queen = 12, King = 13. <br><br>\n",
    "Consider when we draw three cards, we set X to be the value of the first card drawn ($X \\in \\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13\\}$) each with probability $\\frac{1}{13}$. We set Y to be the sum of the next two resulting draws ($Y \\in \\{2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26\\}$). The probability of each of these outcomes is reliant on $X$ since drawing a card with the same value as that drawn in $X$ is reduced from $\\frac{4}{52} = \\frac{1}{13}$ to $\\frac{3}{51}$ and therefore does not stay constant. Further, the probabilities are reduced again on the second draw in $Y$, reducing the proabability of drawing the same card as chosen previously for $Y$.\n",
    "<br><br>\n",
    "Consider, from knowing $X$ and $Y$, we want to know what cards were drawn. Obviously, its fairly impossible to accurately know what the cards drawn were since we start and finish with a model that is fairly uniform regardless of which cards were actually drawn. However, we can still model this to some effect, hopefully at least making some knowledgable decisions as follows.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Defining the deck of cards\n",
    "We can first define a deck of cards which allows us to draw cards with the correct probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the deck of cards\n",
    "import random\n",
    "\n",
    "class deck:\n",
    "\n",
    "    def __init__(self, nVals:int=13, nEach:int=4):\n",
    "        # values and probabilities\n",
    "        self.vals = [n for n in range(1, nVals+1)]\n",
    "        self.probs = nEach\n",
    "\n",
    "        # the cards themselves\n",
    "        self.cards = []\n",
    "        for v in self.vals:\n",
    "            for p in range(self.probs):\n",
    "                self.cards.append(v)\n",
    "    \n",
    "    def deck(self):\n",
    "        return self.cards\n",
    "\n",
    "    def draw(self, nCards:int=1):\n",
    "        cache = []\n",
    "        for i in range(nCards):\n",
    "            # shuffle the deck and take the top card\n",
    "            for i in range(5): random.shuffle(self.cards)\n",
    "            cache.append(self.cards.pop(0))\n",
    "\n",
    "        return cache\n",
    "\n",
    "    def probability(self, card:int=1):\n",
    "        return self.cards.count(card)/len(self.cards)\n",
    "\n",
    "    def value(self, cards:list):\n",
    "        return sum(cards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4, 5, 5, 5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9, 9, 9, 10, 10, 10, 10, 11, 11, 11, 11, 12, 12, 12, 12, 13, 13, 13, 13]\n",
      "X = 2\n",
      "Y = 22\n"
     ]
    }
   ],
   "source": [
    "# draw some cards\n",
    "d = deck()\n",
    "print(d.deck())\n",
    "\n",
    "# event X (draw the first card)\n",
    "D_1 = d.draw(1) \n",
    "print(f\"X = {d.value(D_1)}\") \n",
    "\n",
    "# event Y (draw the next 2 cards)\n",
    "D_2 = d.draw(2) \n",
    "print(f\"Y = {d.value(D_2)}\") "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since $X$ is defined as the value of the first drawn card ($D_1$), it is easy to figure out which card was drawn for event $X$. In other words, $p(D_1|X)=1$ since if $X$ is known, then the card itself is known. In the example drawn above, $X=2$; since only one card was drawn, we know that the card is also $2$. This part is fairly obvious, but gives us information that the probability of drawing $2$ for event $Y$ is reduced. \n",
    "<br><br>\n",
    "Although I don't show this here, we can develop a dynamic programming solution to find the possible solutions for $Y$. Some potential solutions are $\\{13, 9\\}, \\{12, 10\\}, \\{11, 11\\}$, etc. Since we did not recieve any additional information from event $X$ in this case, we effectively have equal probability of choosing the correct values that brought about $Y$. We can right this as a probability function as follows where $Y_1$ and $Y_2$ are the individual draws which create the result $Y$. Therefore, the probability that we are trying to find is $p(Y_1,Y_2|X,Y)$. \n",
    "<br><br>\n",
    "We can immediately reduce the number of combinations to those values which sum to Y and assemble our probabilities from these values. If $Y=22$, then the possible combinations of cards are only 3: {13, 9}, {12, 10}, {11, 11} where we do not care about the order of the cards being drawn. Since none of the combinations inlcude the value $2$, we do not need to account for its changed probability of being selected. Therefore, we can select one of these combinations at random as a guess for the cards drawn. \n",
    "<br><br>\n",
    "Since we effectively have an equal probability that any of the guesses outlined above are correct, say we guess that the cards drawn in event $Y$ ($FD_2$, $FD_3$) are (11, 11). This is a valid guess and has the same probabilty of being right as the true answer outlined below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 9]\n"
     ]
    }
   ],
   "source": [
    "# show the cards drawn for event Y\n",
    "print(D_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that although my guess above of {11, 11} is incorrect, our mathematical thinking process was correct."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### E.2 A continuous inference problem\n",
    "This past summer, I interned at Surgo Health, a company that is trying to solve healthcare problems by looking and social and behavioral contexts of patients. In doing so, they exploit causal machine learning methods to better understand and classify patients and their actions. Of course, this requires massive datasets, with my manager briefly explaining that they often avoid causal ML on datasets with fewer than 10,000 samples. Because of the lack of datasets that are readily available, part of my internship included building a generative network that would be able to generate causally-linked data across 50+ discrete features. This work ended up being the inspiration behind me taking this course, but left me with a specific question - How might we go about building bayesian networks for continuous features. As far as I could see, doing so with discrete variables was hard enough, but allows one to bin values. Making causal predictions across continous features felt somewhat far-fetched. Therefore, for this exploration, I decided to look into several papers and websites that explain continous bayesian networks.<br><br>\n",
    "Looking ahead in the textbook, I was able to find a section on bayesian networks with continuous variables. It seems that implementing this as a generative model would not be entirely difficult since we can define a causal relationship via a function. Similarly, implementing a mixed model using both continuous and discrete values would mean generating values similarly as done using the continuous model and then adding a discretization step where a threshold is applied to create $n$ distinct classes.<br><br>\n",
    "Below, I have tried to implement a small continuous generative network with three nodes which create a v-structure. A v-structure looks as follows: ![](v-structure.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can define a node $A$, $B$, and $V$ shown above by its relationship with it's child node. For simplicity, I use a linear relationship shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Node:\n",
    "\n",
    "    def __init__(self, m:float=1, b:float=0) -> None:\n",
    "        self.slope = m\n",
    "        self.intercept = b\n",
    "        self.out = None\n",
    "\n",
    "    def propogate(self, input:np.array):\n",
    "        self.out = input * self.slope + self.intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.66662417 2.17961209 1.57043584 1.11726065 2.50628165]\n",
      "[-0.73056406 -0.76323252 -0.71923614 -0.74444095 -0.78672049]\n"
     ]
    }
   ],
   "source": [
    "# define the parent nodes\n",
    "A = Node(m=3.1, b=1.1)\n",
    "B = Node(m=0.08, b=-0.79)\n",
    "\n",
    "# pass inputs to the parent nodes to determine the input for node V\n",
    "A.propogate(np.random.beta(1,1,5))\n",
    "B.propogate(np.random.beta(1,1,5))\n",
    "\n",
    "# view the outputs\n",
    "print(A.out)\n",
    "print(B.out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the output above, the input to node $V$ would be somewhat difficult to define, but we can default this to be an additive relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14.68030052  7.08189789  4.25599853  1.86409853  8.59780582]\n"
     ]
    }
   ],
   "source": [
    "# define node V\n",
    "V = Node(m=5, b=0)\n",
    "\n",
    "# define the input to V and propogate\n",
    "V_in = np.add(A.out, B.out)\n",
    "V.propogate(V_in)\n",
    "\n",
    "# print output\n",
    "print(V.out)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This short exploration very crudely defined a generative model to create causally-linked variables. To make this more complete, I would initialize $A$, $B$, and $V$ as Nodes in a graph which could then be used to generate values automatically with one propogation call. One thing that strikes me is the diversity of the distribution at the end of out the output from node $V$. Seeing as this generative model only has 3 nodes with fairly simple linear relationships, working backwards to regain the knowledge of slope/intercept seems much harder than using discrete variables. Hopefully, I can continue to explore this in another exploration."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
